{"name":"Blackhole","tagline":"Yet another logging library.","body":"# Welcome to Blackhole documentation.\r\n\r\n# Architecture\r\n\r\nBlackhole was originally conceived as project with clearly separated entities, or modules. Mainly this decision was made because the project can be easily tested and expanded if it consists of independent entities than with the coupled ones.\r\n\r\nLet's start our description with the fact that we represent Blackhole logger as the production line on which some cargos are transported and some work is done with them. This can be represented schematically as follows:\r\n\r\n![Alt text](http://3hren.github.io/blackhole/images/architecture.png)\r\n\r\nThe main transport unit in our case - is log event.\r\n\r\nInternally Blackhole events are mutual attributes container. Event is considered valid if there is at least one attribute in it. At this point let's talk what attributes are.\r\n\r\n## Attributes\r\n\r\nNowadays logs are much more than just a message with attached timestamp and severity level and [Logstash](http://logstash.net)'s experience proves that. Of course that information provides a fairly comprehensive view about whatâ€™s going on and how important occurred event is, but the main problem that the event itself is completely unstructured and it's quite difficult to use in a further processing like extracting all logs with specific value in message.\r\n\r\nImagine that you are logging some http request. How do you form your logging event? Well, personally I'll write something like this:\r\n```\r\n[2014-03-30 15:30:00.000000] [INFO]: GET '/index/type/id' failed with 404: document not found\r\n```\r\n\r\nEven there we can see additional log event's properties:\r\n* HTTP method: GET\r\n* URI: /index/type/id\r\n* HTTP status code: 404\r\n* HTTP error reason: document not found\r\n\r\nSee, even that simple log event can be typized (or structured) for further processing. What kind of processing? Well, are you seriously going to analyze your logs via parsing it with grep or other similar tool?\r\n\r\nNot only it is inefficient, but also does not guarantee a positive result if the format changes with time. Much better is to put your events into special typed document-oriented database, like ElasticSearch which provides out of the box almost instantly search and analyze.\r\n\r\nSo, in Blackhole everything that relates to log event - is an attribute actually. Attribute itself is represented by value-scale pair, where value has variant type (which isn't sound very surprisingly in C++), and the scale determines attribute's mapping to one of the following groups:\r\n* Local: user's attributes;\r\n* Event: attributes, that doesn't specified by user, like message or timestamp;\r\n* Global: logger's object specific attributes, which can be attached to the logger object and which are transported with it;\r\n* Thread: thread-specific attributes, like thread id;\r\n* Universe: program global attributes, like process id.\r\n\r\nAlso every attribute has its name, which in summary gives a complete picture of the log event.\r\n\r\n## Log Event\r\n\r\nReturning back to the log event, I repeat that log event - is just a set of typed attributes. In our case it will be:\r\n```\r\n[timestamp: 2014-03-28 15:30:00.000000]\r\n[severity: 3]\r\n[message: request failed]\r\n[method: GET]\r\n[uri: /index/type/id]\r\n[status: 404]\r\n[reason: document not found]\r\n```\r\n\r\nAll this attributes gives fully representation of event occurred. Moreover, it can be easily analyzed and indexed for further search.\r\n\r\nReturn to the consideration architecture scheme in more detail. We see, that all further manipulations with log events are occurred in logger object.\r\n\r\n## Filtering\r\n\r\nAfter sending attributes into logger object, they are pre-filtered. Since we have nothing but attributes in the log event, filtering performs on them. For example we can make filter, that only passes log events with severity level more than 3 (INFO) or by presence of some attribute (like urgent tag). Blackhole allows you to configure filtering in two ways: by specifying some functional object which accepts attributes set and returns boolean value, determining if the event pass filtering or not; or by using built-in filter DSL (will described later).\r\n\r\nFiltered events are sent into the main part of logger - frontends, which can be one ore more.\r\n\r\n## Frontend\r\n\r\nFrontend consists of a simple pair of formatter-sink, and it is responsible for communication between them. If the standard contract between formatter and sink is not enough, you can always implement your own specialization of frontent's template class and use it. But it will be described later. For now we look at the each frontend's blocks: formatters and sinks.\r\n\r\n### Formatter\r\n\r\nFormatter module is responsible for translating log event into the string. Why string? Because for almost every case that you can imagine exactly string representation of log event is used.\r\n - Writing log into files on the HDD? Definitely string!\r\n - Syslog? Sure.\r\n - NT events, sockets, streams? String again (event obfuscated or strongly formatted like jsoned, msgpacked or protobuffed string).\r\n\r\nThus, formatter's objects always produce strings.\r\n\r\nBlackhole has some predefined formatters that we briefly enumerate. More detail description will be discussed later hereinafter:\r\n* String by pattern: builds string by specified pattern using attributes provided;\r\n* Json: builds completely json tree, custom tree structure is supported as like as custom nodes renaming; \r\n* Msgpack: behaves just like json formatter, but builds msgpacked object.\r\n\r\nAfter formatting we have log event's string representation, and (we are almost done with it) the last thing we can do with that string - is to send it into the final destination appointment. It is the part where sinks comes at the first place.\r\n\r\n### Sink\r\n\r\nSink module is responsible for final sending formatted message into its final destination. It can be file, socket, syslog or whatever else. At this moment some already implemented sinks are:\r\n* Null: sends messages into, damn, nothing. Useful in testing;\r\n* Stream: prints messages into standard outputs, like stdout or stderr;\r\n* Files: sends messages into specified file. Multiple file handling are supported including file naming by pattern depending on log event's actual attributes. Also file rotation can be flexibly configured;\r\n* Syslog: sends messages into *nix syslog using standard glibc syslog interface functions. Facility, identity and other options can be also easily configured;\r\n* Socket: sends message into specified UDP or TCP socket (synchronously at this time).\r\n\r\nHere lifetime of log event ends.\r\n\r\n## Repository.\r\n\r\nClass apart is the repository singleton, which is responsible for the registration of all possible types of loggers that will be used in your application, adding typical configurations and, surprisingly, creating logger objects.\r\n\r\nIt should be considered just as a large factory.\r\n\r\n# Tutorial\r\n\r\n# Blackhole in detail\r\n\r\n## Registering own attributes\r\n\r\n## Formatters\r\n\r\n## Sinks\r\n\r\n## Filter DSL\r\n\r\n# Extending Blackhole\r\n\r\n## Writing own formatter\r\n\r\n## Writing own sink\r\n\r\n## Writing own frontend\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}